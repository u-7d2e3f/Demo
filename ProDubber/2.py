import re
import os
import shutil
from datetime import datetime
from torch.utils.tensorboard import SummaryWriter

# --- é…ç½® ---
LOG_FILE_PATH = "output/stage2/train.log"
# ç»Ÿä¸€ä¿å­˜åˆ°æ­¤æ ¹ç›®å½•
BASE_LOG_DIR = "output/tensorboard"
# å®šä¹‰å…·ä½“çš„è¿è¡Œå­ç›®å½•ï¼Œè¿™æ · TensorBoard æ‰èƒ½æ­£ç¡®åˆ†ç±»æ˜¾ç¤º
RUN_DIR = os.path.join(BASE_LOG_DIR, "reconstructed_with_time")

# ä½ ç¡®è®¤çš„ï¼š1 è½®è¿­ä»£ 3200 æ¬¡
STEPS_PER_EPOCH = 3200 

# ä¸¥æ ¼å¯¹é½ train_second.py çš„ TensorBoard è·¯å¾„æ˜ å°„
TAG_MAPPING = {
    "Loss": "train/mel_loss",
    "Gen Loss": "train/gen_loss",
    "Disc Loss": "train/d_loss",
    "Dur Loss": "train/dur_loss",
    "CE Loss": "train/ce_loss",
    "LM Loss": "train/slm_loss",
    "Norm Loss": "train/norm_loss",
    "F0 Loss": "train/F0_loss",
    "Sty Loss": "train/sty_loss",
    "Diff Loss": "train/diff_loss"
}

def reconstruct():
    if not os.path.exists(LOG_FILE_PATH):
        print(f"âŒ æ‰¾ä¸åˆ°æ—¥å¿—: {LOG_FILE_PATH}")
        return

    # ç¯å¢ƒå‡†å¤‡ï¼šæ¸…ç†æ—§æ•°æ®
    if os.path.exists(RUN_DIR):
        shutil.rmtree(RUN_DIR)
    os.makedirs(RUN_DIR, exist_ok=True)

    # åˆå§‹åŒ– Writer
    writer = SummaryWriter(log_dir=RUN_DIR)
    
    # æ ¸å¿ƒæ­£åˆ™ï¼šåŒæ—¶åŒ¹é…æ—¶é—´æˆ³ã€Epoch å’Œ Step
    # ç¤ºä¾‹è¡Œ: INFO:2026-01-03 13:38:30,080: Epoch [1/3000], Step [100], Loss: ...
    main_pattern = re.compile(r"INFO:(\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2},\d{3}):\s+Epoch\s+\[(\d+)/.*?Step\s+\[(\d+)\]")
    metric_pattern = re.compile(r"(\b[\w\s]*?Loss):\s+([\d.]+)")

    matched_rows = 0
    total_scalars = 0

    print(f"ğŸš€ æ­£åœ¨è¿˜åŸæ•°æ®åˆ° {RUN_DIR}ï¼Œæ­£åœ¨æ³¨å…¥åŸå§‹æ—¶é—´æˆ³...")

    with open(LOG_FILE_PATH, 'r', encoding='utf-8') as f:
        for line in f:
            if "Epoch" not in line or "Step" not in line:
                continue

            # 1. æå–å…ƒæ•°æ®ï¼ˆæ—¶é—´ã€è½®æ¬¡ã€æ­¥æ•°ï¼‰
            main_match = main_pattern.search(line)
            if main_match:
                time_str = main_match.group(1)      # 2026-01-03 13:38:30,080
                epoch = int(main_match.group(2))
                step_in_epoch = int(main_match.group(3))

                # 2. å°†å­—ç¬¦ä¸²æ—¶é—´è½¬ä¸º Unix æ—¶é—´æˆ³ (ç§’)
                # %f å¯¹åº”æ—¥å¿—ä¸­çš„æ¯«ç§’éƒ¨åˆ†
                dt_obj = datetime.strptime(time_str, "%Y-%m-%d %H:%M:%S,%f")
                wall_time = dt_obj.timestamp()

                # 3. è®¡ç®—å…¨å±€è¿ç»­æ­¥æ•° (Global Step)
                global_step = (epoch - 1) * STEPS_PER_EPOCH + step_in_epoch
                
                # 4. æå–è¯¥è¡Œå†…æ‰€æœ‰çš„ Loss é¡¹
                metrics = metric_pattern.findall(line)
                
                row_has_data = False
                for label, value in metrics:
                    label = label.strip()
                    tag = TAG_MAPPING.get(label)
                    if tag:
                        # æ ¸å¿ƒä¿®æ”¹ï¼šé€šè¿‡ walltime å¼ºåˆ¶æŒ‡å®šè¯¥æ•°æ®ç‚¹çš„ç‰©ç†æ—¶é—´
                        writer.add_scalar(tag, float(value), global_step, walltime=wall_time)
                        total_scalars += 1
                        row_has_data = True
                
                if row_has_data:
                    matched_rows += 1

    # å¼ºåˆ¶åˆ·ç›˜å¹¶é‡Šæ”¾æ–‡ä»¶
    writer.flush()
    writer.close()
    
    print("-" * 40)
    print(f"âœ¨ è¿˜åŸå®Œæˆï¼")
    print(f"âœ… æˆåŠŸæå–çœŸå®æ—¶é—´åæ ‡ç‚¹: {matched_rows} ä¸ªèŠ‚ç‚¹")
    print(f"ğŸ”¢ å†™å…¥æ€»è®¡æ ‡é‡æ•°å€¼: {total_scalars} ä¸ª")
    print(f"ğŸ“‚ å­˜å‚¨è·¯å¾„: {os.path.abspath(RUN_DIR)}")
    print(f"ğŸ‘‰ å¯åŠ¨æŒ‡ä»¤: tensorboard --logdir={BASE_LOG_DIR} --port=6012")

if __name__ == "__main__":
    reconstruct()